{"cells":[{"metadata":{"trusted":true},"cell_type":"code","source":"# Importing important libraries and modules\nimport cv2\nimport os\nimport glob\nimport gc\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom keras.layers import Dropout, Conv2D, Dense, BatchNormalization, AveragePooling2D, MaxPooling2D, Flatten, GlobalAveragePooling2D\nfrom keras.models import Sequential, load_model\nfrom keras.applications.xception import Xception\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import accuracy_score","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# We have to read the data from a file which contains data in the form of image. \n# The folder is named as 'train' and it contains images of different breed of dogs and for label corresponding to each image we will need to read labels.csv\n\n# First of all we will extract the detail of all the data and save all of them in terms of dataframe with foldername, imagename, objectname and labels\ndetail = sorted(glob.glob(\"../input/dog-breed-identification/train/*\"))\nfoldername = [str(i.split(\"in/\")[0]) + \"in\" for i in detail]\nimagename = [str(i.split(\"/\")[4]) for i in detail]\nlabel = np.array((pd.read_csv('../input/dog-breed-identification/labels.csv'))[\"breed\"])\n\n# Defining dataframe and saving all the extracted information in that dataframe\ndata_detail = pd.DataFrame() \ndata_detail[\"foldername\"] = foldername\ndata_detail[\"imagename\"] = imagename\ndata_detail[\"label\"] = label\n\n\n# Analying the train data detail\nprint(\"\\nNumber of images in training set = \"+str(len(detail)))\nprint(data_detail.columns)\ndata_detail.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Checking the no of images we have for each class\nfig = plt.figure(figsize = (40, 10))\nax = fig.add_axes([0,0,1,1])\nax.set_title(\"labels in Data set\", fontsize = 50)\nsns.countplot(x = \"label\", data = data_detail)\nfor i in ax.patches:\n    ax.text(x = i.get_x() + 0.2, y = i.get_height()+1.5, s = str(i.get_height()), fontsize = 10, color = \"black\")\nplt.xlabel(\"\")\nplt.ylabel(\"Count\", fontsize = 35)\nplt.tick_params(labelsize = 5)\nplt.xticks(rotation = 90)\nplt.show()               # Clearly it shows that there is a case of class imbalance here","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Splitting training set into initial training set and test set\ntrain_data_detail, test_data_detail = train_test_split(data_detail, stratify=data_detail[\"label\"], test_size = 0.08)\n\n# Splitting training data into final training set and cross validation set\ntrain_data_detail, cv_data_detail = train_test_split(train_data_detail, stratify=train_data_detail[\"label\"], test_size = 0.086956)\ntrain_data_detail.shape, test_data_detail.shape, cv_data_detail.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Resetting index of train, cross validation and test set\ntrain_data_detail.reset_index(inplace = True, drop = True)\ncv_data_detail.reset_index(inplace = True, drop = True)\ntest_data_detail.reset_index(inplace = True, drop = True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# plotting  and printing distribution of each class in all train, cross validation and test set\n\n# for training data.................................................................................................................\nfig = plt.figure(figsize = (40, 10))\nax = fig.add_axes([0,0,1,1])\nax.set_title(\"labels in Training Data set\", fontsize = 50)\nsns.countplot(x = \"label\", data = train_data_detail)\nfor i in ax.patches:\n    ax.text(x = i.get_x() + 0.2, y = i.get_height(), s = str(i.get_height()), fontsize = 10, color = \"black\")\nplt.xlabel(\"\")\nplt.ylabel(\"Count\", fontsize = 35)\nplt.tick_params(labelsize = 5)\nplt.xticks(rotation = 90)\nplt.show()\n\n# for cross validation data............................................................................................................\nfig = plt.figure(figsize = (40, 10))\nax = fig.add_axes([0,0,1,1])\nax.set_title(\"labels in cv Data set\", fontsize = 50)\nsns.countplot(x = \"label\", data = cv_data_detail)\nfor i in ax.patches:\n    ax.text(x = i.get_x() + 0.2, y = i.get_height(), s = str(i.get_height()), fontsize = 10, color = \"black\")\nplt.xlabel(\"\")\nplt.ylabel(\"Count\", fontsize = 35)\nplt.tick_params(labelsize = 5)\nplt.xticks(rotation = 90)\nplt.show()\n\n# for test data............................................................................................................................\nfig = plt.figure(figsize = (40, 10))\nax = fig.add_axes([0,0,1,1])\nax.set_title(\"labels in test Data set\", fontsize = 50)\nsns.countplot(x = \"label\", data = test_data_detail)\nfor i in ax.patches:\n    ax.text(x = i.get_x() + 0.2, y = i.get_height(), s = str(i.get_height()), fontsize = 10, color = \"black\")\nplt.xlabel(\"\")\nplt.ylabel(\"Count\", fontsize = 35)\nplt.tick_params(labelsize = 5)\nplt.xticks(rotation = 90)\nplt.show()\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# To do tranfer learning creating a base model from VGG-16 pre trained model on Imagenet datset\nbase_model = Xception(weights='imagenet', include_top=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Changing the data into an array of pixels and labels so that it can be fed into the model expect test which is for prediction only\n# Initially it was in the form of a DataFrame\n# Also Creating bottleneck features from base model and storing them","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# for training data\ntrain_x = []\ntrain_y = []\nfor i in range(len(train_data_detail)):\n        path1 = train_data_detail[\"foldername\"][i]\n        path2 = train_data_detail[\"imagename\"][i]\n        image = cv2.imread(os.path.join(path1, path2))\n        image = cv2.resize(image, (224,224))\n        #here, we are normalizing the images\n        image = image/255.0 \n        image = image.reshape(1,224,224,3)\n        image = base_model.predict(image)\n        image = image.reshape(image.shape[1],image.shape[2],image.shape[3] )\n        #Creating and saving each image in the form of numerical data in an array \n        train_x.append(image)\n        #appending corresponding labels \n        train_y.append(train_data_detail['label'][i])  \n        if i%500 == 0:\n            print(\"no of images processed =\",i)\ntrain_x = np.array(train_x,dtype=np.uint8)\ntrain_y = np.array(pd.get_dummies(train_y),dtype=np.uint8)\nprint(\" for training data \", train_x.shape, train_y.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# for test data\ncv_x = []\ncv_y = []\nfor i in range(len(cv_data_detail)):\n        path1 = cv_data_detail[\"foldername\"][i]\n        path2 = cv_data_detail[\"imagename\"][i]\n        image = cv2.imread(os.path.join(path1, path2))\n        image = cv2.resize(image, (224,224))\n        #here, we are normalizing the images\n        image = image/255.0 \n        image = image.reshape(1,224,224,3)\n        image = base_model.predict(image)\n        image = image.reshape(image.shape[1],image.shape[2],image.shape[3] ) \n        #Creating and saving each image in the form of numerical data in an array \n        cv_x.append(image)\n        #appending corresponding labels \n        cv_y.append(cv_data_detail['label'][i]) \n        if i%500 == 0:\n            print(\"no of images processed =\",i)\ncv_x = np.array(cv_x,dtype=np.uint8)\ncv_y = np.array(pd.get_dummies(cv_y),dtype=np.uint8)\nprint(\" for cv data \",cv_x.shape, cv_y.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Defining a model \ndef model():\n    model = Sequential()\n    model.add(GlobalAveragePooling2D(input_shape=train_x.shape[1:]))\n    model.add(Dropout(0.3))\n    model.add(Dense(120, activation='softmax'))\n    \n    return model\nmodel = model()\nmodel.summary() ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Compiling and running the model\nmodel.compile(loss = 'categorical_crossentropy', optimizer = \"adam\", metrics = [\"accuracy\"])\nhist = model.fit(train_x, train_y, validation_data=(cv_x, cv_y), epochs = 25)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# deleting some data to free up ram\ndel train_x\ndel train_y\ndel cv_x\ndel cv_y\ngc.collect()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# visualizing losses and accuracy with epochs \nepoch_number = []\nfor epoch in range(25):\n    epoch_number.append(epoch + 1)\ntrain_loss = hist.history['loss']\nval_loss   = hist.history['val_loss']\ntrain_acc  = hist.history['accuracy']\nval_acc    = hist.history['val_accuracy']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# printing a table depicting the detail about the trained model\nlog_frame = pd.DataFrame(columns = [\"Epoch\", \"Train_Loss\", \"Train_Accuracy\", \"CV_Loss\", \"CV_Accuracy\"])\nlog_frame[\"Epoch\"] = epoch_number\nlog_frame[\"Train_Loss\"] = train_loss\nlog_frame[\"Train_Accuracy\"] = train_acc\nlog_frame[\"CV_Loss\"] = val_loss\nlog_frame[\"CV_Accuracy\"] = val_acc \nlog_frame","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# plotting epoch vs loss\ndef plotting(epoch, train_loss, CV_loss, title):\n    fig, axes = plt.subplots(1,1, figsize = (12, 8))\n    axes.plot(epoch, train_loss, color = 'red', label = \"Train\")\n    axes.plot(epoch, CV_loss, color = 'blue', label = \"CV\")\n    axes.set_title(title, fontsize = 25)\n    axes.set_xlabel(\"Epochs\", fontsize = 20)\n    axes.set_ylabel(\"Loss\", fontsize = 20)\n    axes.grid()\n    axes.legend(fontsize = 20)\n\nplotting(list(log_frame[\"Epoch\"]), list(log_frame[\"Train_Loss\"]), list(log_frame[\"CV_Loss\"]), \"EPOCH VS LOSS\") ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# plotting epoch vs accuracy\ndef plotting(epoch, train_acc, CV_acc, title):\n    fig, axes = plt.subplots(1,1, figsize = (12, 8))\n    axes.plot(epoch, train_acc, color = 'red', label = \"Train_Accuracy\")\n    axes.plot(epoch, CV_acc, color = 'blue', label = \"CV_Accuracy\")\n    axes.set_title(title, fontsize = 25)\n    axes.set_xlabel(\"Epochs\", fontsize = 20)\n    axes.set_ylabel(\"Accuracy\", fontsize = 20)\n    axes.grid()\n    axes.legend(fontsize = 20)\n\nplotting(list(log_frame[\"Epoch\"]), list(log_frame[\"Train_Accuracy\"]), list(log_frame[\"CV_Accuracy\"]), \"EPOCH VS ACCURACY\") ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# for cv data\ntest_x = []\ntest_y = []\nfor i in range(len(test_data_detail)):\n        path1 = test_data_detail[\"foldername\"][i]\n        path2 = test_data_detail[\"imagename\"][i]\n        image = cv2.imread(os.path.join(path1, path2))\n        image = cv2.resize(image, (224,224))\n        #here, we are normalizing the images\n        image = image/255.0 \n        image = image.reshape(1,224,224,3)\n        image = base_model.predict(image)\n        image = image.reshape(image.shape[1],image.shape[2],image.shape[3] ) \n        #Creating and saving each image in the form of numerical data in an array \n        test_x.append(image)\n        #appending corresponding labels \n        test_y.append(test_data_detail['label'][i])  \ntest_x = np.array(test_x,dtype=np.uint8)\ntest_y = np.array(pd.get_dummies(test_y),dtype=np.uint8)\nprint(\" for test data \",test_x.shape, test_y.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# predicting on test data\ntest_predict = model.predict(test_x)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# log loss on test data\nfrom sklearn.metrics import log_loss\nloss = log_loss(test_y, test_predict)\nloss","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# free up ram\ndel test_x\ndel test_y\ndel test_predict\ngc.collect()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# We also need to read the test data for prediction from a file which contains data in the form of image. \n# The folder is named as 'test' and it contains images different breed of dogs\n\n# First of all we will extract the detail of all the data and save all of them in terms of dataframe with foldername and imagename only\ndetail = sorted(glob.glob(\"../input/dog-breed-identification/test/*\"))\nfoldername = [str(i.split(\"st/\")[0]) + \"st\" for i in detail]\nimagename = [str(i.split(\"/\")[4]) for i in detail]\n\n# Defining dataframe and saving all the extracted information in that dataframe\ntest_data_for_prediction_detail = pd.DataFrame() \ntest_data_for_prediction_detail[\"foldername\"] = foldername\ntest_data_for_prediction_detail[\"imagename\"] = imagename\n\n# Analying the test data set for prediction detail\nprint(\"\\nNumber of images in test data set for prediction  = \"+str(len(detail)))\nprint(test_data_for_prediction_detail.columns)\ntest_data_for_prediction_detail.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Changing the data into an array of pixels and labels so that it can be fed into the model for prediction \n# Initially it was in the form of a DataFrame\n\n# for test data for prediction data\nprediction = []\nfor i in range(len(test_data_for_prediction_detail)):\n        path1 = test_data_for_prediction_detail[\"foldername\"][i]\n        path2 = test_data_for_prediction_detail[\"imagename\"][i]\n        image = cv2.imread(os.path.join(path1, path2))\n        image = cv2.resize(image, (224,224))\n        #here, we are normalizing the images\n        image = image/255.0 \n        image = image.reshape(1,224,224,3)\n        image = base_model.predict(image)\n        image = image.reshape(image.shape[1],image.shape[2],image.shape[3] ) \n        #Creating and saving each image in the form of numerical data in an array \n        prediction.append(image) \n        if i%500 == 0:\n            print(\"no of images processed =\",i)\nprediction = np.array(prediction,dtype=np.uint8)\nprint(\" for test data for prediction \", prediction.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Now prediction on data to be predicted\nprediction_predict = model.predict(prediction)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Free up ram\ndel prediction\ngc.collect()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"prediction_predict","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Making new dataframe with id and all the classes and then overlaping with prediction\nlabels = pd.read_csv('/kaggle/input/dog-breed-identification/labels.csv')\nclasses = sorted(list(set(labels['breed'])))\nsubmission = pd.DataFrame(columns=[\"id\"] + list(classes))\ntest_path = \"../input/dog-breed-identification/test\"\nsubmission[\"id\"] = sorted([os.path.splitext(path)[0] for path in os.listdir(test_path)])\nsubmission.loc[:,list(classes)]= prediction_predict","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Final submission file\nsubmission","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Saving the submission file\nsubmission.to_csv('submission.csv', index = False)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}